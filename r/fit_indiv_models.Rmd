
Setup 
```{r}
# clean slate to be sure
rm(list = ls())

# check for pacman package and install if not found
if (!require("pacman")) install.packages("pacman")
pacman::p_load(afex, readr, dplyr, tidyr, ggplot2, cowplot, devtools, here, tidyverse, magrittr, reshape2, rjags, coda, lattice, broom, ggpubr, ggmcmc, foreach, doParallel, ggpol, ggstatsplot, ggcorrplot)

# load the metaSDT package from github
if (!require("metaSDT")) devtools::install_github("craddm/metaSDT")

source(here("r", "remove_outliers.R"))
source(here("r", "trials2counts.R"))
source(here("r", "metad_indiv.R"))
source(here("r", "fit_mle.R"))
source(here("r", "Bayes_metad_hierarchical.R"))
source(here("r", "fit_hMetaCorr.R"))


```



```{r}
# read in the data

metacognition_trial_data <- read_csv(here("data_summary", "metacognition_TrialData_master.csv"), 
    col_types = cols(confidence = col_double(), 
        rt_conf = col_double()))

# set modality as factor
metacognition_trial_data$modality <- as.factor(metacognition_trial_data$modality )

# remove any rows containing NaNs (i.e., missing data)

metacognition_trial_data <- na.omit(metacognition_trial_data)

head(metacognition_trial_data)



```

Trial-level exclusion:
```{r}


metadata <- metacognition_trial_data %>%
  group_by(subject, modality) %>%
  mutate(rt = remove_outliers(rt)) # remove RT outliers using MAD Rule - SEE PRE REG

metadata <- na.omit(metadata)

#Exclude those with rt <50ms 
metadata <- metadata%>%filter(rt>=0.05) 


#Exclude those with less than 50% trials (i.e. less than 100 or 50) within condition
metadata<-metadata%>%mutate(modality=as.factor(modality))
metadatac<-metadata #create new dataframe
metadatac$modality <-fct_collapse (metadatac$modality, trivia = c("Calories", "GDP"))#combine the two trivia tasks in new dataframe
metadatac <- metadatac %>%
  group_by(subject, modality)%>% count(subject) #count number of trials
excD <- subset(metadatac, metadatac$n<100) 
excID <-unique(excD$subject) #Identify participants for exclusion
metadata <- subset(metadata, !is.element(metadata$subject, excID)) ##Exclude IDs from that vector in original dataframe

#Check staircase procedure: First create individual dataframes. 
memory <- metadata %>%filter(modality == c('memory')) 
knowledge <- metadata %>%filter(modality == c('trivia')) 
percept <- metadata %>%filter(modality == c('vision')) 

#Perception: 
Pplot_list = list() 

for(t in 1:length(percept$subject)) { 
  Pplots <- (ggplot(percept) +
    geom_step(aes(x=(trial), y=contrast)) +
    xlab("trial") +
    ylab("contrast") + theme_bw() + facet_wrap(percept$subject))
 Pplot_list[[t]] = Pplots
  } #Create plots for each participant

#save to pdf with 20 participants on each page: 
pdf("staircaseplots.pdf")
for (k in 20:length(percept$subject)) {
    print(Pplot_list[[k]])
}
dev.off()

## MUST DE_COLLAPSE TRIVIA FOR THE NEXT ANALYSIS/FIGURE OUT HOW TO DO ANOTHER DATAFRAME HERE. 

glimpse(metadata)


```

Let's loop over subjects now and fit the MLE model. 

```{r}

subjects = unique(metadata$subject)
modalities = as.character(unique(metadata$modality))


# setup cluster
n.cores <- parallel::detectCores() - 1 # 1 less than max cores to prevent crashing

#create the cluster
my.cluster <- parallel::makeCluster(
  n.cores, 
  type = "PSOCK"
)

#register it to be used by %dopar%
doParallel::registerDoParallel(cl = my.cluster)


# fit all subjects in parallel


source(here("r", "parMLEfit.R"))



# stop the cluster

stopCluster(cl = my.cluster)

# write out the data file

write.csv(fit_data, file = here("data_summary","mle_mratio_fit_data.csv"))


head(fit_data)
```

Group-level exclusion based on MAD rule (confidence, d', criterion)
```{r}

#exclude those where mratio could not be estimated  
metadata_exc <- fit_data%>%filter(mratio!="NaN")

#Exclude outliers based on MAD rule (confidence, d' and criterion)
#Confidence:
Avgmeta <- metadata %>% 
  group_by(subject, modality) %>% 
  summarise(avg_conf=mean(confidence, na_rm=TRUE)) #Mean confidence for each modality

#join Avgmeta with fit_data 
fitAvg_data<- fit_data %>% full_join(Avgmeta, 
                                   by= c('subject'='subject', 
                                         'modality' = 'modality'))
metadata_exc <- fitAvg_data%>%
  group_by(subject, modality) %>%
  mutate(avg_conf = remove_outliers(avg_conf)) # remove RT outliers using MAD Rule 

metadata_exc <- na.omit(metadata_exc)

#d' 
metadata_exc <- fitAvg_data%>%
  group_by(subject, modality) %>%
  mutate(da = remove_outliers(da)) # remove RT outliers using MAD Rule 

metadata_exc <- na.omit(metadata_exc)

#criterion: INCLUDE THIS IN THE FIT RESULTS
metadata_exc <- fitAvg_data%>%
  group_by(subject) %>%
  mutate(da = remove_outliers(cr)) # remove RT outliers using MAD Rule 

metadata_exc <- na.omit(metadata_exc)

head(metadata_exc)


```

Let's plot the M-ratio by condition      #(after some filtering)

```{r}

#plot_data <- filter(fit_data_wide, mratio > 0)
#plot_data <- filter(fit_data_wide, da > 0)

#plot_data <- filter(fit_data_wide, da > 0.5)

#plot_data <- plot_data %>%
 # group_by(subject, modality) %>%
#  mutate(da = remove_outliers(da))

#plot_data <-  na.omit(plot_data)


#plot_data <- plot_data %>%
 # group_by(subject, modality) %>%
  #mutate(mratio = remove_outliers(mratio))

#plot_data <-  na.omit(plot_data)

ggplot(metadata_exc, aes(x = modality, y = mratio)) +
  geom_boxjitter() +
  ggtitle("Metacognitive Efficiency")

ggplot(metadata_exc, aes(x = modality, y = avg_conf)) +
  geom_boxjitter() +
  ggtitle("Metacognitive Bias")

ggplot(metadata_exc, aes(x = modality, y = mda)) +
  geom_boxjitter() +
  ggtitle("Metacognitive Sensitivity")

ggplot(metadata_exc, aes(x = modality, y = da)) +
  geom_boxjitter() +
  ggtitle("Cognitive Sensitivity")


#ggplot(fit_data, aes(x = modality, y = mratio)) +
#  geom_boxjitter() +
 # ggtitle("unfiltered")


#model = aov_ez(data = plot_data, id = "subject", dv = "mratio", within = c("modality"))
#print(model)
```
Pivot the data frame to wide. 

```{r}

fit_data_wide <- metadata_exc %>% pivot_wider(
  names_from = modality,
  values_from = c(da, mda, mratio)
)
  

write.csv(fit_data_wide, file = here("data_summary","mle_mratio_fit_data_wide.csv"))

head(fit_data_wide)
```


Correlation  between domains: 
```{r}

ggcorrmat(data = fit_data_wide[ , 10:13],
          type= "robust", p.adjust.method = "none")+
  ggtitle("unfiltered")


ggcorrmat(data = fit_data_wide[ , 10:13],
          type= "robust", p.adjust.method = "none")+
  ggtitle("unfiltered")


#Plot Correlations: 


```


```{r}
ggcorrmat(data = fit_data_wide[ , 10:13],
          type= "parametric", p.adjust.method = "none")+
  ggtitle("unfiltered")



plot_data_wide <- plot_data %>% pivot_wider(
  names_from = modality,
  values_from = c(da, mda, mratio)
)

ggcorrmat(data = plot_data_wide[ , 10:13],
          type= "parametric", p.adjust.method = "none")+
  ggtitle("filtered")


```

Filter wide data
```{r}

fit_data_wide <- fit_data_wide %>%
  mutate(across(starts_with("da")), ~ remove_outliers(.x))



```



```{r}

library(ez)
library(emmeans)
library(afex)
library(ggpol)
library(ggbeeswarm)
afex_plot(model, x = "modality", error = "within")
```


```{r}
ggplot(plot_data, aes(x = modality, y = mratio, fill = modality)) +
  geom_violin() +
  geom_boxjitter(
            width = 0.5,
            jitter.color = "gray",
            jitter.width = 0.1,
            jitter.height = 0,
            outlier.color = "gray",
            outlier.intersect = TRUE)


```

```{r}
jasp_data <- plot_data
jasp_data <- pivot_wider(data = jasp_data, names_from = modality, values_from = c(da, mda, mratio)) 


write.csv(jasp_data, "M_Ratio_summary.csv")
```








loop and get Individual Bayesian fit

```{r}

subjects = unique(metadata$subject)
modalities = as.character(unique(metadata$modality))

## THIS NEEDS TO BE EDITED - IT IS NOT THE RIGHT FIT.. THE ORIGINAL SCRIPT IS BELOW (NO PARALLEL)


# setup cluster
n.cores <- parallel::detectCores() - 1 # 1 less than max cores to prevent crashing

#create the cluster
my.cluster <- parallel::makeCluster(
  n.cores, 
  type = "PSOCK"
)

#register it to be used by %dopar%
doParallel::registerDoParallel(cl = my.cluster)


# fit all subjects in parallel


source(here("r", "parindBayes.R"))


# stop the cluster

stopCluster(cl = my.cluster)

# write out the data file

write.csv(indBayes_data, file = here("data_summary","indvBay_mratio_fit_data.csv"))


head(indBayes_data)








# THIS IS THE ORIGINAL SCRIPT: 


fit_data_bayes = data.frame()

for(s in 1:length(subjects)) {
#foreach (s = 1:length(subjects), .combine=rbind) %dopar%  { # for parallel computing.. wip.. 
  
  for(m in 1:length(modalities)) {
    
    tryCatch(
      expr = {
        # subset data for subject and modality 
        subdata <- filter(metadata, subject == subjects[s] & modality == modalities[m])  
        
        #transform trial data to counts
        newlist <- trials2counts(subdata$signal, subdata$response, subdata$confidence,7, padAmount = 0,padCells=1)
        nR_S1 <- unlist(newlist[1], recursive = TRUE, use.names = TRUE)
        nR_S2 <- unlist(newlist[2], recursive = TRUE, use.names = TRUE)
        
        #fit model
        fit <- metad_indiv(nR_S1, nR_S2)
        #glimpse(subdata)
        #Sys.sleep(1)
        
        output <- data.frame("subject" = subjects[s],"modality"=modalities[m],
                             "da" = fit$d, "mda" = fit$mean,
                             "mratio" = fit$mratio)  
        
        fit_data_bayes <- rbind(fit_data_bayes, output)
      },
      error = function(e) {
        message("* caught an error on subject ", subjects[s])
        print(e)
        output <- data.frame("subject" = subjects[s],
                             "modality"=modalities[m],"da" = NaN,
                             "mda" = NaN, "mratio" = NaN) 
        fit_data_bayes <- rbind(fit_data_bayes, output)
        
        }
      
      
    )
    
  }
  
}

write.csv(fit_data_bayes, file = "bayes_mratio_fit_data.csv")
```

```{r}
head(fit_data_bayes)

plot_data <- fit_data_bayes



plot_data <- filter(fit_data_bayes, mratio > 0)
plot_data <- filter(plot_data, da > 0)
plot_data <- filter(plot_data, mda > 0)



trim_data = plot_data %>%
  group_by(modality) %>%
  mutate_at(vars(da, mda, mratio), funs(remove_outliers))
  

ggplot(trim_data, aes(x = modality, y = mratio))+
  geom_boxplot()

jasp_data <- trim_data
jasp_data <- pivot_wider(data = jasp_data, names_from = modality, values_from = c(da, mda, mratio)) 


write.csv(jasp_data, "bayes_MR_summary.csv")


```

```{r}
remove_outliers <- function(x, na.rm = TRUE, ...) {
  qnt <- quantile(x, probs=c(.25, .75), na.rm = na.rm, ...)
  H <- 1.5 * IQR(x, na.rm = na.rm)
  y <- x
  y[x < (qnt[1] - H)] <- NA
  y[x > (qnt[2] + H)] <- NA
  y
}
```





Hierarchical Bayesian fit + direct Correlation: Running in parallel

```{r}

subjects = unique(metadata$subject)
modalities = as.character(unique(metadata$modality))

## THIS IS NOT WORKING ATM


# setup cluster
n.cores <- parallel::detectCores() - 1 # 1 less than max cores to prevent crashing

#create the cluster
my.cluster <- parallel::makeCluster(
  n.cores, 
  type = "PSOCK"
)

#register it to be used by %dopar%
doParallel::registerDoParallel(cl = my.cluster)

# fit all subjects in parallel

source(here("r", "parHmetaCor.R"))

# stop the cluster
stopCluster(cl = my.cluster)


# save output
write.csv(Hmeta_data, file = here("data_summary","mle_mratio_fit_data.csv"))


head(Hmeta_data)


```

